{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ZsdtkxaGoYLR",
    "outputId": "e4797658-6d0b-48d9-c1b6-7284db4b0ee7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "e6KffM15xgKa"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.metrics import precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "id": "pMUPIfdW1xSy"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True ,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    "    )\n",
    "\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False ,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5B1dppMX2MQ1"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "    'test': DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "nQAnlZQq3QY2",
    "outputId": "d92ef036-f2e4-4ca8-ef7e-1edc3d05e8bd"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x78024f530a90>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x780250245750>}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "mPEqWH8Y3cus"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "    self.conv2_drop = nn.Dropout2d() #normalization, deactivates layer\n",
    "    self.fc1 = nn.Linear(320, 50)\n",
    "    self.fc2 = nn.Linear(50, 10) # 10 because 10 digits and softmax function will be used - prob for every digit\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "    x = x.view(-1, 320)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.dropout(x, training=self.training)\n",
    "    x = self.fc2(x)\n",
    "\n",
    "    return F.softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "v-27Q4DU68qU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 50 == 0 :\n",
    "      print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
    "\n",
    "\n",
    "def test():\n",
    "  model.eval()\n",
    "\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "\n",
    "  all_preds = []\n",
    "  all_targets = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for data, target in loaders['test']:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output = model(data)\n",
    "      test_loss += loss_fn(output, target).item()\n",
    "      pred = output.argmax(dim=1, keepdim = True)\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "      all_preds.extend(pred.cpu().numpy())\n",
    "      all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "  precision = precision_score(all_targets, all_preds, average='macro')\n",
    "  recall = recall_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "  print(f'Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "  test_loss /= len(loaders['test'].dataset)\n",
    "  print(f'\\nTest set: Average loss: {test_loss: .4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct/len(loaders[\"test\"].dataset):.0f}%\\n)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "vdcmep4JACYZ",
    "outputId": "8538511c-425e-4900-f1ac-99ac9ec0052f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.304752\n",
      "Train Epoch: 1 [5000/60000 (8%)]\t2.091468\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.815430\n",
      "Train Epoch: 1 [15000/60000 (25%)]\t1.779651\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.682752\n",
      "Train Epoch: 1 [25000/60000 (42%)]\t1.631898\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.627197\n",
      "Train Epoch: 1 [35000/60000 (58%)]\t1.646579\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.645466\n",
      "Train Epoch: 1 [45000/60000 (75%)]\t1.623046\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.709655\n",
      "Train Epoch: 1 [55000/60000 (92%)]\t1.599739\n",
      "Precision: 0.9333, Recall: 0.9328\n",
      "\n",
      "Test set: Average loss:  0.0153, Accuracy 9334/10000 (93%\n",
      ")\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.566857\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 2 [5000/60000 (8%)]\t1.580302\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.618145\n",
      "Train Epoch: 2 [15000/60000 (25%)]\t1.609087\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.573242\n",
      "Train Epoch: 2 [25000/60000 (42%)]\t1.610754\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.572949\n",
      "Train Epoch: 2 [35000/60000 (58%)]\t1.563399\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.532866\n",
      "Train Epoch: 2 [45000/60000 (75%)]\t1.565576\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.600026\n",
      "Train Epoch: 2 [55000/60000 (92%)]\t1.617979\n",
      "Precision: 0.9525, Recall: 0.9523\n",
      "\n",
      "Test set: Average loss:  0.0151, Accuracy 9527/10000 (95%\n",
      ")\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.546927\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 3 [5000/60000 (8%)]\t1.540888\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.549324\n",
      "Train Epoch: 3 [15000/60000 (25%)]\t1.573651\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.568155\n",
      "Train Epoch: 3 [25000/60000 (42%)]\t1.537431\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.574079\n",
      "Train Epoch: 3 [35000/60000 (58%)]\t1.569740\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.510148\n",
      "Train Epoch: 3 [45000/60000 (75%)]\t1.524587\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.513896\n",
      "Train Epoch: 3 [55000/60000 (92%)]\t1.527760\n",
      "Precision: 0.9592, Recall: 0.9589\n",
      "\n",
      "Test set: Average loss:  0.0150, Accuracy 9592/10000 (96%\n",
      ")\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.572217\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 4 [5000/60000 (8%)]\t1.509059\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.609605\n",
      "Train Epoch: 4 [15000/60000 (25%)]\t1.563730\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.534501\n",
      "Train Epoch: 4 [25000/60000 (42%)]\t1.565388\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.605954\n",
      "Train Epoch: 4 [35000/60000 (58%)]\t1.544684\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.554476\n",
      "Train Epoch: 4 [45000/60000 (75%)]\t1.567564\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.567645\n",
      "Train Epoch: 4 [55000/60000 (92%)]\t1.505454\n",
      "Precision: 0.9634, Recall: 0.9632\n",
      "\n",
      "Test set: Average loss:  0.0150, Accuracy 9634/10000 (96%\n",
      ")\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.558694\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 5 [5000/60000 (8%)]\t1.585189\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.547144\n",
      "Train Epoch: 5 [15000/60000 (25%)]\t1.518558\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.554826\n",
      "Train Epoch: 5 [25000/60000 (42%)]\t1.549497\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.559206\n",
      "Train Epoch: 5 [35000/60000 (58%)]\t1.513771\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.510437\n",
      "Train Epoch: 5 [45000/60000 (75%)]\t1.533445\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.533319\n",
      "Train Epoch: 5 [55000/60000 (92%)]\t1.532312\n",
      "Precision: 0.9655, Recall: 0.9653\n",
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9655/10000 (97%\n",
      ")\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.515792\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 6 [5000/60000 (8%)]\t1.537952\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.565322\n",
      "Train Epoch: 6 [15000/60000 (25%)]\t1.518279\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.528797\n",
      "Train Epoch: 6 [25000/60000 (42%)]\t1.572660\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.523793\n",
      "Train Epoch: 6 [35000/60000 (58%)]\t1.505754\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.536599\n",
      "Train Epoch: 6 [45000/60000 (75%)]\t1.555816\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.536873\n",
      "Train Epoch: 6 [55000/60000 (92%)]\t1.526571\n",
      "Precision: 0.9684, Recall: 0.9685\n",
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9685/10000 (97%\n",
      ")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 7 [0/60000 (0%)]\t1.542814\n",
      "Train Epoch: 7 [5000/60000 (8%)]\t1.570860\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.522809\n",
      "Train Epoch: 7 [15000/60000 (25%)]\t1.495202\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.521220\n",
      "Train Epoch: 7 [25000/60000 (42%)]\t1.535131\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.489777\n",
      "Train Epoch: 7 [35000/60000 (58%)]\t1.555300\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.546716\n",
      "Train Epoch: 7 [45000/60000 (75%)]\t1.560494\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.539654\n",
      "Train Epoch: 7 [55000/60000 (92%)]\t1.518007\n",
      "Precision: 0.9716, Recall: 0.9714\n",
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9715/10000 (97%\n",
      ")\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.503370\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 8 [5000/60000 (8%)]\t1.492774\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.512595\n",
      "Train Epoch: 8 [15000/60000 (25%)]\t1.543322\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.500460\n",
      "Train Epoch: 8 [25000/60000 (42%)]\t1.545646\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.512477\n",
      "Train Epoch: 8 [35000/60000 (58%)]\t1.544722\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.501861\n",
      "Train Epoch: 8 [45000/60000 (75%)]\t1.507082\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.526539\n",
      "Train Epoch: 8 [55000/60000 (92%)]\t1.502506\n",
      "Precision: 0.9719, Recall: 0.9721\n",
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9720/10000 (97%\n",
      ")\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.510419\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 9 [5000/60000 (8%)]\t1.555480\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.571538\n",
      "Train Epoch: 9 [15000/60000 (25%)]\t1.513664\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.499050\n",
      "Train Epoch: 9 [25000/60000 (42%)]\t1.512058\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.585837\n",
      "Train Epoch: 9 [35000/60000 (58%)]\t1.491888\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.560326\n",
      "Train Epoch: 9 [45000/60000 (75%)]\t1.491927\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.532446\n",
      "Train Epoch: 9 [55000/60000 (92%)]\t1.521052\n",
      "Precision: 0.9730, Recall: 0.9730\n",
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9730/10000 (97%\n",
      ")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 10 [0/60000 (0%)]\t1.495480\n",
      "Train Epoch: 10 [5000/60000 (8%)]\t1.525319\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.502686\n",
      "Train Epoch: 10 [15000/60000 (25%)]\t1.513064\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.536533\n",
      "Train Epoch: 10 [25000/60000 (42%)]\t1.516859\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.516126\n",
      "Train Epoch: 10 [35000/60000 (58%)]\t1.511727\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.505105\n",
      "Train Epoch: 10 [45000/60000 (75%)]\t1.497818\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.548641\n",
      "Train Epoch: 10 [55000/60000 (92%)]\t1.523689\n",
      "Precision: 0.9734, Recall: 0.9733\n",
      "\n",
      "Test set: Average loss:  0.0149, Accuracy 9734/10000 (97%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nI-_ix1iAuNG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "38e2addf-e10c-4b20-8a8b-c338bdccc72f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files found: ['9.2.png', '7.1.png', '7.2.png', '6.3.png', '.ipynb_checkpoints', '9.3.png', '8.1.png', '4.2.png', '1.1.png', '2.3.png', '3.3.png', '2.1.png', '2.2.png', '5.1.png', '3.1.png', '0.3.png', '6.2.png', '0.2.png', '6.1.png', '5.3.png', '4.3.png', '3.2.png', '1.3.png', '8.3.png', '1.2.png', '8.2.png', '5.2.png', '4.1.png', '0.1.png', '7.3.png', '9.1.png']\n",
      "Loaded 30 custom handwritten digit images.\n",
      "Recognition accuracy on custom handwritten digits: 20.00%\n",
      "ðŸ”´ ERROR: True digit: 9, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 7, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 7, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 6, Model predicted: 0\n",
      "ðŸ”´ ERROR: True digit: 9, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 8, Model predicted: 0\n",
      "ðŸ”´ ERROR: True digit: 4, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 1, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 2, Model predicted: 3\n",
      "ðŸ”´ ERROR: True digit: 2, Model predicted: 3\n",
      "ðŸ”´ ERROR: True digit: 5, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 3, Model predicted: 5\n",
      "ðŸ”´ ERROR: True digit: 6, Model predicted: 3\n",
      "ðŸ”´ ERROR: True digit: 6, Model predicted: 3\n",
      "ðŸ”´ ERROR: True digit: 4, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 3, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 1, Model predicted: 5\n",
      "ðŸ”´ ERROR: True digit: 8, Model predicted: 0\n",
      "ðŸ”´ ERROR: True digit: 1, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 8, Model predicted: 0\n",
      "ðŸ”´ ERROR: True digit: 4, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 0, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 7, Model predicted: 8\n",
      "ðŸ”´ ERROR: True digit: 9, Model predicted: 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-24-e2395ce73220>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the folder containing custom handwritten digit images\n",
    "custom_data_path = \"my_digits/\"\n",
    "\n",
    "# Image transformation to match MNIST format (28x28, grayscale, tensor)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure image is in grayscale\n",
    "    transforms.Resize((28, 28)),                  # Resize to 28x28 pixels\n",
    "    transforms.ToTensor(),                        # Convert image to tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))     # Normalize as in MNIST\n",
    "])\n",
    "\n",
    "# Lists to store images and labels\n",
    "custom_images = []\n",
    "custom_labels = []\n",
    "\n",
    "# Debug: list files in the folder\n",
    "files_in_dir = os.listdir(custom_data_path)\n",
    "print(\"Files found:\", files_in_dir)\n",
    "\n",
    "# Iterate through all PNG files in the folder\n",
    "for file in files_in_dir:\n",
    "    if file.lower().endswith(\".png\"):\n",
    "        img_path = os.path.join(custom_data_path, file)\n",
    "        try:\n",
    "            # Open and transform the image\n",
    "            img = Image.open(img_path)\n",
    "            img = transform(img)\n",
    "            custom_images.append(img)\n",
    "\n",
    "            # Extract label from the filename (e.g., \"0.1.png\" -> label 0)\n",
    "            label = int(file.split('.')[0])\n",
    "            custom_labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "# Ensure that images were successfully loaded\n",
    "if not custom_images:\n",
    "    raise RuntimeError(\"No images were loaded. Please verify the folder path and file formats.\")\n",
    "\n",
    "# Convert lists to PyTorch tensors\n",
    "custom_images = torch.stack(custom_images)\n",
    "custom_labels = torch.tensor(custom_labels)\n",
    "\n",
    "print(f\"Loaded {len(custom_images)} custom handwritten digit images.\")\n",
    "\n",
    "# Set the model to evaluation mode (assuming `model` and `device` are already defined)\n",
    "model.eval()\n",
    "\n",
    "# Move custom images and labels to the same device as the model\n",
    "custom_images = custom_images.to(device)\n",
    "custom_labels = custom_labels.to(device)\n",
    "\n",
    "# Obtain predictions from the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(custom_images)\n",
    "    predictions = outputs.argmax(dim=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = (predictions == custom_labels).sum().item()\n",
    "accuracy = 100. * correct / len(custom_labels)\n",
    "print(f\"Recognition accuracy on custom handwritten digits: {accuracy:.2f}%\")\n",
    "\n",
    "# Analyze and print misclassifications\n",
    "for i in range(len(custom_labels)):\n",
    "    true_label = custom_labels[i].item()\n",
    "    predicted_label = predictions[i].item()\n",
    "    if true_label != predicted_label:\n",
    "        print(f\"ðŸ”´ ERROR: True digit: {true_label}, Model predicted: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Load MNIST dataset using torchvision\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Convert dataset images and labels to numpy arrays.\n",
    "# Flatten each 28x28 image to a vector of size 784.\n",
    "X_train = train_dataset.data.numpy().reshape(-1, 28*28)\n",
    "y_train = train_dataset.targets.numpy()\n",
    "X_test = test_dataset.data.numpy().reshape(-1, 28*28)\n",
    "y_test = test_dataset.targets.numpy()\n",
    "\n",
    "# Create and train the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Compute performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Recognition Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {recall:.4f}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqoErr-tEWbA",
    "outputId": "a692a93e-16e8-4c4a-e317-4b70a4bc73b0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recognition Accuracy: 0.9705\n",
      "Precision: 0.9704\n",
      "Sensitivity (Recall): 0.9702\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
